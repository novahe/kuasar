# Kuasar E2E æµ‹è¯•æ”¹è¿›å»ºè®®

åŸºäºå¯¹ kata-containers é¡¹ç›®çš„åˆ†æï¼Œä»¥ä¸‹æ˜¯ Kuasar E2E æµ‹è¯•çš„æ”¹è¿›å»ºè®®ã€‚

## ä¸€ã€ç°çŠ¶å¯¹æ¯”åˆ†æ

### Kata-Containers E2E æµ‹è¯•æ¶æ„

```
tests/
â”œâ”€â”€ integration/          # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ kubernetes/      # 70+ ä¸ª bats æµ‹è¯•
â”‚   â”œâ”€â”€ cri-containerd/
â”‚   â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ nerdctl/
â”‚   â””â”€â”€ nydus/
â”œâ”€â”€ functional/           # åŠŸèƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ kata-agent-apis/
â”‚   â”œâ”€â”€ kata-monitor/
â”‚   â””â”€â”€ tracing/
â”œâ”€â”€ stability/           # ç¨³å®šæ€§æµ‹è¯•
â”‚   â”œâ”€â”€ agent_stability_test.sh
â”‚   â”œâ”€â”€ kubernetes_soak_test.sh
â”‚   â””â”€â”€ stressng/
â””â”€â”€ metrics/             # æ€§èƒ½æµ‹è¯•
    â”œâ”€â”€ cpu/
    â”œâ”€â”€ density/
    â”œâ”€â”€ disk/
    â”œâ”€â”€ network/
    â””â”€â”€ storage/
```

**æµ‹è¯•ç‰¹ç‚¹ï¼š**
- **æ¡†æ¶**: Bats (Bash Automated Testing System)
- **è¦†ç›–åº¦**: 70+ Kubernetes åœºæ™¯ï¼Œæ¶µç›–æ ¸å¿ƒåŠŸèƒ½
- **æµ‹è¯•ç±»å‹**: é›†æˆã€åŠŸèƒ½ã€ç¨³å®šæ€§ã€æ€§èƒ½
- **CI é›†æˆ**: GitHub Actions è‡ªåŠ¨åŒ–è¿è¡Œ
- **å·¥å…·é“¾**: ä¸°å¯Œçš„æµ‹è¯•è¾…åŠ©å·¥å…·å’Œè„šæœ¬

### Kuasar E2E æµ‹è¯•ç°çŠ¶

```
tests/e2e/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs           # æµ‹è¯•æ¡†æ¶ (700 è¡Œ)
â”‚   â”œâ”€â”€ main.rs          # äºŒè¿›åˆ¶å…¥å£
â”‚   â””â”€â”€ tests.rs         # æµ‹è¯•ç”¨ä¾‹ (200 è¡Œ)
â””â”€â”€ configs/             # æµ‹è¯•é…ç½®
```

**æµ‹è¯•ç‰¹ç‚¹ï¼š**
- **æ¡†æ¶**: Rust + tokio
- **è¦†ç›–åº¦**: ä»… runc runtime åŸºç¡€ç”Ÿå‘½å‘¨æœŸæµ‹è¯•
- **æµ‹è¯•ç±»å‹**: åªæœ‰åŸºç¡€çš„é›†æˆæµ‹è¯•
- **æµ‹è¯•åœºæ™¯**: éå¸¸æœ‰é™

---

## äºŒã€æ ¸å¿ƒå·®è·

| ç»´åº¦ | Kata-Containers | Kuasar | å·®è· |
|------|----------------|--------|------|
| **æµ‹è¯•æ¡†æ¶** | Bats + Bash | Rust + tokio | âœ… æŠ€æœ¯é€‰å‹åˆç†ï¼Œä½†ç¼ºå°‘å·¥å…·é“¾ |
| **Kubernetes é›†æˆ** | 70+ æµ‹è¯•ç”¨ä¾‹ | 0 | âŒ å®Œå…¨ç¼ºå¤± |
| **Runtime è¦†ç›–** | kata-runtime | ä»… runc | âš ï¸  éœ€æ‰©å±•åˆ° vmm/wasm/quark |
| **åŠŸèƒ½æµ‹è¯•** | å…¨é¢ï¼ˆç½‘ç»œã€å­˜å‚¨ã€å®‰å…¨ï¼‰ | å‡ ä¹æ—  | âŒ ä¸¥é‡ä¸è¶³ |
| **ç¨³å®šæ€§æµ‹è¯•** | soak/stress æµ‹è¯• | æ—  | âŒ å®Œå…¨ç¼ºå¤± |
| **æ€§èƒ½æµ‹è¯•** | å®Œæ•´çš„ benchmark | æ—  | âŒ å®Œå…¨ç¼ºå¤± |
| **CI é›†æˆ** | GitHub Actions | æœ‰ Makefile.e2e | âš ï¸  éœ€å®Œå–„ |

---

## ä¸‰ã€æ”¹è¿›å»ºè®®

### é˜¶æ®µ 1: æ‰©å±•åŸºç¡€æµ‹è¯•è¦†ç›–ï¼ˆä¼˜å…ˆçº§ï¼šğŸ”´ é«˜ï¼‰

#### 1.1 å®Œå–„ Runtime ç”Ÿå‘½å‘¨æœŸæµ‹è¯•

**ç›®æ ‡**: è¦†ç›–æ‰€æœ‰ Kuasar runtime çš„æ ¸å¿ƒåŠŸèƒ½

```rust
// tests/e2e/src/runtime_tests.rs

#[tokio::test]
#[serial]
async fn test_vmm_runtime_lifecycle() {
    // VMM (Cloud Hypervisor/QEMU/StratoVirt)
    // 1. åˆ›å»º VM
    // 2. åœ¨ VM å†…åˆ›å»ºå®¹å™¨
    // 3. éªŒè¯å®¹å™¨è¿è¡Œ
    // 4. æ¸…ç†
}

#[tokio::test]
#[serial]
async fn test_wasm_runtime_lifecycle() {
    // Wasm (WasmEdge/Wasmtime)
}

#[tokio::test]
#[serial]
async fn test_quark_runtime_lifecycle() {
    // Quark app-kernel
}
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ¯ä¸ª runtime è‡³å°‘æœ‰ 1 ä¸ª lifecycle æµ‹è¯•
- [ ] æµ‹è¯•å¯ä»¥åœ¨æœ¬åœ°ç¯å¢ƒç¨³å®šè¿è¡Œ
- [ ] æµ‹è¯•å¤±è´¥æ—¶æœ‰æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯

#### 1.2 æ·»åŠ é”™è¯¯åœºæ™¯æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/integration/kubernetes/k8s-oom.bats

```rust
#[tokio::test]
async fn test_container_oom() {
    // 1. åˆ›å»ºå†…å­˜é™åˆ¶å¾ˆå°çš„å®¹å™¨
    // 2. è¿è¡Œå†…å­˜æ¶ˆè€—å‹ä»»åŠ¡
    // 3. éªŒè¯å®¹å™¨è¢« OOMKilled
    // 4. æ£€æŸ¥äº‹ä»¶ä¸ŠæŠ¥
}

#[tokio::test]
async fn test_container_crash_loop_backoff() {
    // 1. åˆ›å»ºå¯åŠ¨å³å¤±è´¥çš„å®¹å™¨
    // 2. éªŒè¯é‡å¯ç­–ç•¥
    // 3. éªŒè¯ backoff æœºåˆ¶
}
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] è‡³å°‘è¦†ç›– 5 ç§å¸¸è§é”™è¯¯åœºæ™¯
- [ ] æ¯ä¸ªåœºæ™¯éƒ½æœ‰æ¸…æ™°çš„éªŒè¯æ­¥éª¤

---

### é˜¶æ®µ 2: Kubernetes é›†æˆæµ‹è¯•ï¼ˆä¼˜å…ˆçº§ï¼šğŸ”´ é«˜ï¼‰

#### 2.1 å¼•å…¥ Kubernetes æµ‹è¯•æ¡†æ¶

**æ–¹æ¡ˆ A**: ä½¿ç”¨ Rust åŸç”Ÿ Kubernetes å®¢æˆ·ç«¯

```toml
# tests/e2e/Cargo.toml
[dependencies]
kube = { version = "0.88", features = ["runtime", "client"] }
k8s-openapi = { version = "0.21", features = ["v1_29"] }
```

```rust
// tests/e2e/src/k8s_tests.rs
use kube::{Client, Api};
use k8s_openapi::api::core::v1::Pod;

#[tokio::test]
#[serial]
async fn test_kubernetes_pod_lifecycle() {
    let client = Client::try_default().await.unwrap();
    let pods: Api<Pod> = Api::default_namespaced(client);

    // åˆ›å»º pod
    let pod = create_test_pod("test-pod");
    let _ = pods.create(&Default::default(), &pod).await.unwrap();

    // ç­‰å¾… Ready
    wait_for_pod_ready(&pods, "test-pod").await;

    // éªŒè¯
    let pod = pods.get("test-pod").await.unwrap();
    assert_eq!(pod.status.unwrap().phase.unwrap(), "Running");

    // æ¸…ç†
    pods.delete("test-pod", &Default::default()).await.unwrap();
}
```

**æ–¹æ¡ˆ B**: ä½¿ç”¨ Bats (ä¸ kata-containers ä¸€è‡´)

```bash
#!/usr/bin/env bats
# tests/e2e/k8s/k8s-pod-lifecycle.bats

load "${BATS_TEST_DIRNAME}/../lib.sh"

setup() {
    setup_common || die "setup_common failed"
}

@test "Pod lifecycle" {
    pod_name="test-pod-${RANDOM}"

    # åˆ›å»º pod
    kubectl create -f "${pod_config_dir}/test-pod.yaml"

    # ç­‰å¾… Ready
    kubectl wait --for=condition=Ready --timeout=$timeout pod "$pod_name"

    # éªŒè¯
    kubectl get pod "$pod_name" | grep "Running"

    # æ¸…ç†
    kubectl delete pod "$pod_name"
}

teardown() {
    teardown_common
}
```

**æ¨è**: **æ–¹æ¡ˆ B (Bats)**ï¼ŒåŸå› ï¼š
1. ä¸ kata-containers ç”Ÿæ€ä¸€è‡´
2. å¯ä»¥å¤ç”¨ kata-containers çš„æµ‹è¯•ç”¨ä¾‹
3. è„šæœ¬æ›´å®¹æ˜“ç»´æŠ¤å’Œç†è§£
4. ç¤¾åŒºæœ‰å¤§é‡ç°æˆçš„æµ‹è¯•ç”¨ä¾‹å¯ä»¥å‚è€ƒ

#### 2.2 æ ¸å¿ƒæµ‹è¯•ç”¨ä¾‹æ¸…å•

å‚è€ƒ kata-containers/tests/integration/kubernetes/ï¼Œå®ç°ä»¥ä¸‹æµ‹è¯•ï¼š

| ç±»åˆ« | æµ‹è¯•ç”¨ä¾‹ | ä¼˜å…ˆçº§ |
|------|---------|--------|
| **åŸºç¡€åŠŸèƒ½** | Pod ç”Ÿå‘½å‘¨æœŸ | ğŸ”´ é«˜ |
| | å®¹å™¨ç”Ÿå‘½å‘¨æœŸ | ğŸ”´ é«˜ |
| | Exec/Attach | ğŸŸ¡ ä¸­ |
| | Logs | ğŸŸ¡ ä¸­ |
| **æ¢é’ˆ** | Liveness probe | ğŸ”´ é«˜ |
| | Readiness probe | ğŸ”´ é«˜ |
| | Startup probe | ğŸŸ¡ ä¸­ |
| **å­˜å‚¨** | EmptyDir | ğŸ”´ é«˜ |
| | HostPath | ğŸŸ¡ ä¸­ |
| | ConfigMap/Secret | ğŸ”´ é«˜ |
| | Persistent Volume | ğŸŸ¡ ä¸­ |
| **ç½‘ç»œ** | Pod é—´é€šä¿¡ | ğŸ”´ é«˜ |
| | Service (ClusterIP) | ğŸ”´ é«˜ |
| | DNS | ğŸ”´ é«˜ |
| | Port Forward | ğŸŸ¡ ä¸­ |
| **å®‰å…¨** | Security Context | ğŸŸ¡ ä¸­ |
| | Seccomp | ğŸŸ¡ ä¸­ |
| | AppArmor | ğŸŸ¢ ä½ |
| **èµ„æº** | CPU é™åˆ¶ | ğŸŸ¡ ä¸­ |
| | å†…å­˜é™åˆ¶ | ğŸŸ¡ ä¸­ |
| | OOM | ğŸ”´ é«˜ |
| **é«˜çº§** | Init Containers | ğŸŸ¡ ä¸­ |
| | Multi-Container Pod | ğŸŸ¡ ä¸­ |
| | Job/CronJob | ğŸŸ¢ ä½ |
| | DaemonSet | ğŸŸ¢ ä½ |

**å®ç°è·¯å¾„**:
1. **Week 1-2**: åŸºç¡€åŠŸèƒ½ï¼ˆPod/Container lifecycleï¼‰
2. **Week 3**: æ¢é’ˆå’Œå­˜å‚¨
3. **Week 4**: ç½‘ç»œå’Œ DNS
4. **Week 5**: å®‰å…¨å’Œèµ„æºé™åˆ¶

---

### é˜¶æ®µ 3: åŠŸèƒ½ä¸“é¡¹æµ‹è¯•ï¼ˆä¼˜å…ˆçº§ï¼šğŸŸ¡ ä¸­ï¼‰

#### 3.1 ç½‘ç»œåŠŸèƒ½æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/metrics/network/

```bash
#!/usr/bin/env bats
# tests/e2e/functional/network/network-latency.bats

@test "Pod network latency" {
    # å¯åŠ¨æµ‹è¯• pod
    kubectl apply -f "${testdata}/network-test-pods.yaml"

    # è¿è¡Œ ping æµ‹è¯•
    LATENCY=$(kubectl exec pod-a -- ping -c 10 pod-b | grep "avg" | awk '{print $4}')

    # éªŒè¯å»¶è¿Ÿ < 10ms
    (( $(echo "$LATENCY < 10" | bc -l) ))
}

@test "Pod network throughput" {
    # ä½¿ç”¨ iperf3 æµ‹è¯•ååé‡
    kubectl apply -f "${testdata}/iperf3-server.yaml"
    kubectl apply -f "${testdata}/iperf3-client.yaml"

    THROUGHPUT=$(kubectl exec iperf-client -- iperf3 -c iperf-server -t 10 | grep "sender" | awk '{print $7}')

    # éªŒè¯ååé‡ > 1 Gbps
    (( $(echo "$THROUGHPUT > 1.0" | bc -l) ))
}
```

#### 3.2 å­˜å‚¨åŠŸèƒ½æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/metrics/storage/fio_test.sh

```bash
#!/usr/bin/env bats
# tests/e2e/functional/storage/fio-performance.bats

@test "Volume IOPS" {
    kubectl apply -f "${testdata}/fio-test.yaml"

    # è¿è¡Œ FIO æµ‹è¯•
    IOPS=$(kubectl exec fio-test -- fio --name=randread --ioengine=libaio --iodepth=16 \
        --rw=randread --bs=4k --direct=1 --size=512M --numjobs=4 --runtime=60 \
        --group_reporting --format=json | jq '.jobs[0].read.iops')

    # éªŒè¯ IOPS > 1000
    [ "$IOPS" -gt 1000 ]
}
```

#### 3.3 VMM ç‰¹å®šåŠŸèƒ½æµ‹è¯•

```bash
#!/usr/bin/env bats
# tests/e2e/functional/vmm/vm-lifecycle.bats

@test "VM hotplug device" {
    # å¯åŠ¨ pod
    kubectl apply -f "${testdata}/pod-with-volume.yaml"

    # éªŒè¯ VM å†…å¯ä»¥çœ‹åˆ°æ–°è®¾å¤‡
    VM_PID=$(get_vm_pid_for_pod "test-pod")
    DEVICE_COUNT=$(sudo nsenter -t $VM_PID -n -- ls /sys/class/block/ | wc -l)

    # æ·»åŠ  volume
    kubectl apply -f "${testdata}/extra-volume.yaml"

    # éªŒè¯è®¾å¤‡å¢åŠ 
    NEW_DEVICE_COUNT=$(sudo nsenter -t $VM_PID -n -- ls /sys/class/block/ | wc -l)
    [ "$NEW_DEVICE_COUNT" -gt "$DEVICE_COUNT" ]
}

@test "VM live migration" {
    # å¦‚æœæ”¯æŒ live migration
    # 1. å¯åŠ¨ VM on node1
    # 2. è¿ç§»åˆ° node2
    # 3. éªŒè¯å®¹å™¨çŠ¶æ€ä¿æŒ
    # 4. éªŒè¯ç½‘ç»œè¿æ¥ä¸ä¸­æ–­
}
```

---

### é˜¶æ®µ 4: ç¨³å®šæ€§æµ‹è¯•ï¼ˆä¼˜å…ˆçº§ï¼šğŸŸ¡ ä¸­ï¼‰

#### 4.1 Soak æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/stability/kubernetes_soak_test.sh

```bash
#!/bin/bash
# tests/e2e/stability/soak-test.sh

set -e

DURATION=${1:-1h}  # é»˜è®¤ 1 å°æ—¶
POD_COUNT=${2:-100}  # é»˜è®¤ 100 ä¸ª pod

echo "Starting soak test: ${POD_COUNT} pods for ${DURATION}"

# åˆ›å»ºå¤§é‡ pod
kubectl apply -f "${testdata}/soak-pods-deployment.yaml"
kubectl scale deployment soak-test --replicas=${POD_COUNT}

# æŒç»­ç›‘æ§
START_TIME=$(date +%s)
END_TIME=$((START_TIME + $(duration_to_seconds $DURATION)))

while [ $(date +%s) -lt $END_TIME ]; do
    # æ£€æŸ¥ pod çŠ¶æ€
    READY_COUNT=$(kubectl get pods -l app=soak-test | grep Running | wc -l)

    if [ "$READY_COUNT" -lt "$POD_COUNT" ]; then
        echo "ERROR: Only ${READY_COUNT}/${POD_COUNT} pods are running"
        kubectl get pods -l app=soak-test
        exit 1
    fi

    # æ£€æŸ¥èµ„æºä½¿ç”¨
    MEMORY_USAGE=$(free -m | grep Mem | awk '{print $3}')
    echo "Memory usage: ${MEMORY_USAGE}MB, Ready pods: ${READY_COUNT}/${POD_COUNT}"

    sleep 60
done

echo "Soak test passed!"
```

#### 4.2 Stress æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/stability/stressng/

```bash
#!/bin/bash
# tests/e2e/stability/stress-test.sh

# CPU å‹åŠ›æµ‹è¯•
@test "CPU stress" {
    kubectl apply -f "${testdata}/stress-cpu.yaml"

    # è¿è¡Œ 10 åˆ†é’Ÿ
    sleep 600

    # éªŒè¯ç³»ç»Ÿæ²¡æœ‰å´©æºƒ
    kubectl get pods | grep stress-cpu | grep Running
}

# å†…å­˜å‹åŠ›æµ‹è¯•
@test "Memory stress" {
    kubectl apply -f "${testdata}/stress-memory.yaml"

    # è¿è¡Œ 10 åˆ†é’Ÿ
    sleep 600

    # éªŒè¯ç³»ç»Ÿæ²¡æœ‰ OOMï¼ˆé™¤äº†é¢„æœŸçš„å®¹å™¨ OOMï¼‰
    kubectl get pods | grep stress-memory
}

# IO å‹åŠ›æµ‹è¯•
@test "IO stress" {
    kubectl apply -f "${testdata}/stress-io.yaml"

    # è¿è¡Œ 10 åˆ†é’Ÿ
    sleep 600

    # éªŒè¯ç³»ç»Ÿå“åº”æ­£å¸¸
    kubectl get nodes
}
```

---

### é˜¶æ®µ 5: æ€§èƒ½æµ‹è¯•ï¼ˆä¼˜å…ˆçº§ï¼šğŸŸ¢ ä½ï¼‰

#### 5.1 å¯åŠ¨æ—¶é—´æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/metrics/time/launch_times.sh

```bash
#!/bin/bash
# tests/e2e/metrics/startup-time.sh

ITERATIONS=100

echo "Measuring container startup time (${ITERATIONS} iterations)"

TOTAL_TIME=0
for i in $(seq 1 $ITERATIONS); do
    START=$(date +%s%N)

    kubectl run test-pod-${i} --image=nginx --restart=Never

    kubectl wait --for=condition=Ready pod/test-pod-${i} --timeout=30s

    END=$(date +%s%N)

    DURATION=$(( (END - START) / 1000000 ))
    TOTAL_TIME=$((TOTAL_TIME + DURATION))

    kubectl delete pod test-pod-${i}
done

AVG_TIME=$((TOTAL_TIME / ITERATIONS))
echo "Average startup time: ${AVG_TIME}ms"

# ä¸ baseline å¯¹æ¯”
if [ $AVG_TIME -gt 5000 ]; then
    echo "ERROR: Startup time too high: ${AVG_TIME}ms"
    exit 1
fi
```

#### 5.2 èµ„æºå¼€é”€æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/metrics/density/memory_usage.sh

```bash
#!/bin/bash
# tests/e2e/metrics/memory-footprint.sh

BASELINE_MEMORY=$(free -m | grep Mem | awk '{print $3}')

# å¯åŠ¨ 100 ä¸ª pod
kubectl apply -f "${testdata}/nginx-deployment.yaml"
kubectl scale deployment nginx --replicas=100

# ç­‰å¾…æ‰€æœ‰ pod Ready
kubectl wait --for=condition=available deployment/nginx --timeout=5m

# æµ‹é‡å†…å­˜ä½¿ç”¨
PEAK_MEMORY=$(free -m | grep Mem | awk '{print $3}')

PER_POD_MEMORY=$(( (PEAK_MEMORY - BASELINE_MEMORY) / 100 ))

echo "Memory per pod: ${PER_POD_MEMORY}MB"

# éªŒè¯å†…å­˜å¼€é”€åˆç†
if [ $PER_POD_MEMORY -gt 50 ]; then
    echo "ERROR: Memory per pod too high: ${PER_POD_MEMORY}MB"
    exit 1
fi
```

#### 5.3 å¯†åº¦æµ‹è¯•

**å‚è€ƒ**: kata-containers/tests/metrics/density/fast_footprint.sh

```bash
#!/bin/bash
# tests/e2e/metrics/pod-density.sh

MAX_PODS=500

echo "Testing maximum pod density"

# é€æ­¥å¢åŠ  pod æ•°é‡
for COUNT in 100 200 300 400 500; do
    echo "Scaling to ${COUNT} pods"
    kubectl scale deployment test-pods --replicas=${COUNT}

    # ç­‰å¾…ç¨³å®š
    sleep 30

    # æ£€æŸ¥æ‰€æœ‰ pod Ready
    READY_COUNT=$(kubectl get pods -l app=test | grep Running | wc -l)

    if [ "$READY_COUNT" -lt "$COUNT" ]; then
        echo "ERROR: Failed to reach ${COUNT} pods. Maximum: ${READY_COUNT}"
        exit 1
    fi

    echo "Successfully running ${READY_COUNT} pods"
done

echo "Pod density test passed: ${MAX_PODS} pods"
```

---

## å››ã€æµ‹è¯•å·¥å…·é“¾å»ºè®¾

### 4.1 é€šç”¨æµ‹è¯•åº“

**å‚è€ƒ**: kata-containers/tests/common.bash

```bash
# tests/e2e/lib/common.sh

# é‡è¯•æœºåˆ¶
kubernetes_retry() {
    local retries=5
    local interval=10
    local count=0

    while [ $count -lt $retries ]; do
        kubectl "$@" && return 0
        count=$((count + 1))
        sleep $interval
    done

    return 1
}

# ç­‰å¾… pod Ready
wait_for_pod() {
    local pod_name=$1
    local timeout=${2:-60}

    kubectl wait --for=condition=Ready --timeout=${timeout}s pod/$pod_name
}

# è·å– pod IP
get_pod_ip() {
    local pod_name=$1
    kubectl get pod $pod_name -o jsonpath='{.status.podIP}'
}

# è·å– VM PID (VMM ä¸“ç”¨)
get_vm_pid() {
    local pod_name=$1

    # æŸ¥æ‰¾å¯¹åº”çš„ hypervisor è¿›ç¨‹
    ps aux | grep "pod-name=${pod_name}" | grep -v grep | awk '{print $2}'
}

# æ‰§è¡Œå‘½ä»¤åˆ° VM å†…éƒ¨
exec_in_vm() {
    local pod_name=$1
    shift

    local vm_pid=$(get_vm_pid $pod_name)
    sudo nsenter -t $vm_pid -n -- "$@"
}
```

### 4.2 æµ‹è¯•æ•°æ®ç®¡ç†

```
tests/e2e/testdata/
â”œâ”€â”€ pods/
â”‚   â”œâ”€â”€ nginx-pod.yaml
â”‚   â”œâ”€â”€ busybox-pod.yaml
â”‚   â””â”€â”€ stress-pod.yaml
â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ nginx-deployment.yaml
â”‚   â””â”€â”€ stress-deployment.yaml
â”œâ”€â”€ volumes/
â”‚   â”œâ”€â”€ emptydir.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â””â”€â”€ pvc.yaml
â”œâ”€â”€ network/
â”‚   â”œâ”€â”€ pod-to-pod.yaml
â”‚   â””â”€â”€ service.yaml
â””â”€â”€ security/
    â”œâ”€â”€ privileged-pod.yaml
    â””â”€â”€ seccomp-pod.yaml
```

### 4.3 CI/CD é›†æˆ

```yaml
# .github/workflows/e2e-tests.yml
name: E2E Tests

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  runc-e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - name: Setup dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y containerd cri-tools
      - name: Run E2E tests
        run: |
          make setup-e2e-env
          make test-e2e-runc

  vmm-e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup VMM
        run: |
          sudo apt-get install -y cloud-hypervisor virtiofsd
          make bin/vmm-sandboxer
          make bin/vmm-task
      - name: Run VMM E2E tests
        run: |
          make test-e2e-vmm

  kubernetes-integration:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Kubernetes
        uses: helm/kind-action@v1
        with:
          version: v0.20.0
      - name: Install containerd
        run: |
          sudo apt-get install -y containerd
      - name: Install Kuasar
        run: |
          make all
          make install
      - name: Run K8s E2E tests
        run: |
          cd tests/e2e/k8s
          ./run_kubernetes_tests.sh
```

---

## äº”ã€å®æ–½è·¯å¾„

### Phase 1: åŸºç¡€å®Œå–„ï¼ˆ1-2 å‘¨ï¼‰

**ç›®æ ‡**: å»ºç«‹å¯è¿è¡Œçš„æµ‹è¯•åŸºç¡€

- [ ] å®Œå–„æ‰€æœ‰ runtime çš„ lifecycle æµ‹è¯•
- [ ] æ·»åŠ é”™è¯¯åœºæ™¯æµ‹è¯•ï¼ˆOOMã€crash loopï¼‰
- [ ] å»ºç«‹æµ‹è¯•æ•°æ®ç›®å½•ç»“æ„
- [ ] ç¼–å†™é€šç”¨æµ‹è¯•åº“

**éªŒæ”¶**: æ‰€æœ‰ runtime è‡³å°‘æœ‰ 1 ä¸ªå¯è¿è¡Œçš„æµ‹è¯•

### Phase 2: Kubernetes é›†æˆï¼ˆ3-4 å‘¨ï¼‰

**ç›®æ ‡**: å®ç°æ ¸å¿ƒ Kubernetes åŠŸèƒ½æµ‹è¯•

- [ ] å¼•å…¥ Bats æµ‹è¯•æ¡†æ¶
- [ ] å®ç° 20 ä¸ªæ ¸å¿ƒæµ‹è¯•ç”¨ä¾‹
- [ ] æ­å»ºæœ¬åœ°æµ‹è¯•ç¯å¢ƒ
- [ ] é›†æˆåˆ° CI

**éªŒæ”¶**: CI ä¸­å¯ä»¥è‡ªåŠ¨è¿è¡Œ K8s æµ‹è¯•

### Phase 3: åŠŸèƒ½æ‰©å±•ï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**: è¦†ç›–ç½‘ç»œã€å­˜å‚¨ã€å®‰å…¨åŠŸèƒ½

- [ ] ç½‘ç»œåŠŸèƒ½æµ‹è¯•ï¼ˆå»¶è¿Ÿã€ååã€DNSï¼‰
- [ ] å­˜å‚¨åŠŸèƒ½æµ‹è¯•ï¼ˆå„ç§ volume ç±»å‹ï¼‰
- [ ] å®‰å…¨åŠŸèƒ½æµ‹è¯•ï¼ˆsecurity contextã€seccompï¼‰

**éªŒæ”¶**: åŠŸèƒ½æµ‹è¯•è¦†ç›–ç‡è¾¾åˆ° 60%

### Phase 4: ç¨³å®šæ€§å’Œæ€§èƒ½ï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**: å»ºç«‹éåŠŸèƒ½æ€§æµ‹è¯•ä½“ç³»

- [ ] Soak æµ‹è¯•ï¼ˆé•¿æ—¶é—´è¿è¡Œï¼‰
- [ ] Stress æµ‹è¯•ï¼ˆå‹åŠ›æµ‹è¯•ï¼‰
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆå¯åŠ¨æ—¶é—´ã€èµ„æºå¼€é”€ï¼‰

**éªŒæ”¶**: å¯ä»¥å®šæœŸè¿è¡Œç¨³å®šæ€§æµ‹è¯•

### Phase 5: æŒç»­ä¼˜åŒ–ï¼ˆæŒç»­ï¼‰

**ç›®æ ‡**: ä¸æ–­æå‡æµ‹è¯•è´¨é‡å’Œæ•ˆç‡

- [ ] æµ‹è¯•è¦†ç›–ç‡åˆ†æ
- [ ] æµ‹è¯•æ‰§è¡Œæ—¶é—´ä¼˜åŒ–
- [ ] æµ‹è¯•ç»“æœå¯è§†åŒ–
- [ ] è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•

---

## å…­ã€å…³é”®æŒ‡æ ‡

### æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡

| ç»´åº¦ | å½“å‰ | ç›®æ ‡ | æ—¶é—´ |
|------|------|------|------|
| Runtime ç±»å‹ | 1/4 | 4/4 | Phase 1 |
| K8s æ ¸å¿ƒåŠŸèƒ½ | 0% | 80% | Phase 2 |
| åŠŸèƒ½ä¸“é¡¹ | 0% | 60% | Phase 3 |
| ç¨³å®šæ€§æµ‹è¯• | 0 | âœ… | Phase 4 |
| æ€§èƒ½åŸºå‡† | 0 | âœ… | Phase 4 |

### è´¨é‡æŒ‡æ ‡

- **æµ‹è¯•é€šè¿‡ç‡**: > 95%
- **æµ‹è¯•æ‰§è¡Œæ—¶é—´**: < 30 åˆ†é’Ÿ
- **Flaky æµ‹è¯•ç‡**: < 5%
- **æµ‹è¯•è¦†ç›–ç‡**: > 70%

---

## ä¸ƒã€èµ„æºéœ€æ±‚

### äººåŠ›

- **æµ‹è¯•å¼€å‘**: 1-2 äºº
- **æµ‹è¯•åŸºç¡€è®¾æ–½**: 0.5 äººï¼ˆå…¼èŒï¼‰
- **CI ç»´æŠ¤**: 0.5 äººï¼ˆå…¼èŒï¼‰

### ç¯å¢ƒ

- **CI ç¯å¢ƒ**: GitHub Actions (å…è´¹)
- **æµ‹è¯•é›†ç¾¤**: 3-5 ä¸ªèŠ‚ç‚¹ï¼ˆå¯é€‰ï¼Œæœ¬åœ°ä¹Ÿå¯ï¼‰
- **æ€§èƒ½æµ‹è¯•**: éœ€è¦ç‰©ç†æœºæˆ–é«˜æ€§èƒ½ VM

---

## å…«ã€æ€»ç»“

Kuasar çš„ E2E æµ‹è¯•è¿˜å¤„äºæ—©æœŸé˜¶æ®µï¼Œç›¸æ¯” kata-containers æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ã€‚å»ºè®®æŒ‰ç…§ä¸Šè¿° 5 ä¸ªé˜¶æ®µé€æ­¥æ¨è¿›ï¼š

1. **Phase 1**: å»ºç«‹åŸºç¡€ï¼ˆ1-2 å‘¨ï¼‰
2. **Phase 2**: Kubernetes é›†æˆï¼ˆ3-4 å‘¨ï¼‰- **æœ€é‡è¦**
3. **Phase 3**: åŠŸèƒ½æ‰©å±•ï¼ˆ2-3 å‘¨ï¼‰
4. **Phase 4**: ç¨³å®šæ€§å’Œæ€§èƒ½ï¼ˆ2-3 å‘¨ï¼‰
5. **Phase 5**: æŒç»­ä¼˜åŒ–ï¼ˆæŒç»­ï¼‰

**å…³é”®æˆåŠŸå› ç´ **:
- ä½¿ç”¨ Bats æ¡†æ¶ï¼ˆä¸ kata-containers å¯¹é½ï¼‰
- ä¼˜å…ˆå®ç° Kubernetes é›†æˆæµ‹è¯•
- å»ºç«‹è‡ªåŠ¨åŒ– CI
- æŒç»­ç»´æŠ¤å’Œæ›´æ–°æµ‹è¯•ç”¨ä¾‹

**é¢„æœŸæ”¶ç›Š**:
- æå‡ä»£ç è´¨é‡å’Œç¨³å®šæ€§
- åŠ å¿«ç‰ˆæœ¬å‘å¸ƒé€Ÿåº¦
- å‡å°‘ç”Ÿäº§ç¯å¢ƒé—®é¢˜
- å¢å¼ºç”¨æˆ·ä¿¡å¿ƒ
